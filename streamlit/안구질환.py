#ë¼ì´ë¸ŒëŸ¬ë¦¬ import
#í•„ìš”í•œ ê²½ìš° install
import streamlit as st
import os
from streamlit_cropper import st_cropper
from PIL import Image
import pandas as pd
import numpy as np
from io import StringIO
import datetime
import matplotlib.pyplot as plt
import matplotlib.image as img
import statsmodels.api as sm
import time
from streamlit_option_menu import option_menu
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchsummary import summary
from torch import optim
from torch.optim.lr_scheduler import StepLR
import sklearn
from sklearn.model_selection import train_test_split
import torchvision
import torchvision.transforms as transforms
from efficientnet_pytorch import EfficientNet
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights

#########################################ì¤‘ìš”###########################################
# cd C:/Users/sook7/Desktop/CUAI í”„ë¡œì íŠ¸/ë°˜ë ¤ë™ë¬¼ ì•ˆêµ¬ì§ˆí™˜ íƒì§€/streamlit
# í„°ë¯¸ë„ì—ì„œ ëª…ë ¹ì–´(streamlit run ì•ˆêµ¬ì§ˆí™˜.py)ë¥¼ ì‹¤í–‰ ì‹œì¼œì£¼ì–´ì•¼ ë¡œì»¬ì—ì„œ ìŠ¤íŠ¸ë¦¼ë¦¿ì´ ì‘ë™í•¨

## ê°€ìƒí™˜ê²½ ì„¤ì • í•„ìš”
# í™œì„±í™” : venv\Scripts\activate
# ë¹„í™œì„±í™” : venv\Scripts\deactivate

#######################################################################################
class BasicBlock(nn.Module):
    expansion = 1
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()

        # BatchNormì— biasê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, conv2dëŠ” bias=Falseë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
        self.residual_function = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(out_channels * BasicBlock.expansion),
        )

        # identity mapping, inputê³¼ outputì˜ feature map size, filter ìˆ˜ê°€ ë™ì¼í•œ ê²½ìš° ì‚¬ìš©.
        self.shortcut = nn.Sequential()

        self.relu = nn.ReLU()

        # projection mapping using 1x1conv
        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels * BasicBlock.expansion)
            )

    def forward(self, x):
        x = self.residual_function(x) + self.shortcut(x)
        x = self.relu(x)
        return x


class BottleNeck(nn.Module):
    expansion = 4
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()

        self.residual_function = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),
            nn.BatchNorm2d(out_channels * BottleNeck.expansion),
        )

        self.shortcut = nn.Sequential()

        self.relu = nn.ReLU()

        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels*BottleNeck.expansion)
            )

    def forward(self, x):
        x = self.residual_function(x) + self.shortcut(x)
        x = self.relu(x)
        return x
class ResNet(nn.Module):
    def __init__(self, block, num_block, num_classes=2, init_weights=True):
        super().__init__()

        self.in_channels=64

        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        )

        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)
        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)
        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)
        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)

        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)

        # weights inittialization
        if init_weights:
            self._initialize_weights()

    def _make_layer(self, block, out_channels, num_blocks, stride):
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_channels, out_channels, stride))
            self.in_channels = out_channels * block.expansion

        return nn.Sequential(*layers)

    def forward(self,x):
        output = self.conv1(x)
        output = self.conv2_x(output)
        x = self.conv3_x(output)
        x = self.conv4_x(x)
        x = self.conv5_x(x)
        x = self.avg_pool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

    # define weight initialization function
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)

def resnet18():
    return ResNet(BasicBlock, [2,2,2,2])

def resnet34():
    return ResNet(BasicBlock, [3, 4, 6, 3])

def resnet50():
    return ResNet(BottleNeck, [3,4,6,3])

def resnet101():
    return ResNet(BottleNeck, [3, 4, 23, 3])

def resnet152():
    return ResNet(BottleNeck, [3, 8, 36, 3])

# ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜
class SingleImageEfficientNet(nn.Module):
    def __init__(self, output_dim):
        super(SingleImageEfficientNet, self).__init__()
        self.model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)
        self.model.classifier = nn.Identity()  # ë§ˆì§€ë§‰ classifier ë ˆì´ì–´ ì œê±° (íŠ¹ì§•ë§Œ ì¶”ì¶œ)
        self.dropout = nn.Dropout(0.2)  # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ 0.2 ì„¤ì •
        self.batch_norm = nn.BatchNorm1d(1280 + 8)  # Batch Normalization layer ì¶”ê°€, ì›-í•« ì¸ì½”ë”© ë²¡í„° ì°¨ì›ë§Œí¼ ì¦ê°€
        self.fc = nn.Linear(1280 + 8, output_dim)  # ëª¨ë¸ì˜ ì¶œë ¥ì„ FC layer í†µê³¼, ì›-í•« ì¸ì½”ë”© ë²¡í„° ì°¨ì›ë§Œí¼ ì¦ê°€

    def forward(self, x, pos_vector):
        x = self.model(x)  # ëª¨ë¸ì— ì´ë¯¸ì§€ë¥¼ ì „ë‹¬í•˜ì—¬ íŠ¹ì§• ì¶”ì¶œ
        x = x.view(x.size(0), -1)
        x = torch.cat((x, pos_vector), dim=1)  # íŠ¹ì§•ê³¼ ì›-í•« ì¸ì½”ë”© ë²¡í„°ë¥¼ ì—°ê²°
        x = self.dropout(x)  # ë“œë¡­ì•„ì›ƒ ì ìš©
        x = self.batch_norm(x)  # Batch Normalization ì ìš©
        x = self.fc(x)  # íŠ¹ì§•ì„ FC layer í†µê³¼
        return x

# Depthwise Separable Convolution
class Depthwise(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()

        self.depthwise = nn.Sequential(
            nn.Conv2d(in_channels, in_channels, 3, stride=stride, padding=1, groups=in_channels, bias=False),
            nn.BatchNorm2d(in_channels),
            nn.ReLU6(),
        )

        self.pointwise = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU6()
        )

    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        return x


# Basic Conv2d
class BasicConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):
        super().__init__()

        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs),
            nn.BatchNorm2d(out_channels),
            nn.ReLU()
        )

    def forward(self, x):
        x = self.conv(x)
        return x


# MobileNetV1
class MobileNet(nn.Module):
    def __init__(self, width_multiplier, num_classes=2, init_weights=True):
        super().__init__()
        self.init_weights=init_weights
        alpha = width_multiplier

        self.conv1 = BasicConv2d(3, int(32*alpha), 3, stride=2, padding=1)
        self.conv2 = Depthwise(int(32*alpha), int(64*alpha), stride=1)
        # down sample
        self.conv3 = nn.Sequential(
            Depthwise(int(64*alpha), int(128*alpha), stride=2),
            Depthwise(int(128*alpha), int(128*alpha), stride=1)
        )
        # down sample
        self.conv4 = nn.Sequential(
            Depthwise(int(128*alpha), int(256*alpha), stride=2),
            Depthwise(int(256*alpha), int(256*alpha), stride=1)
        )
        # down sample
        self.conv5 = nn.Sequential(
            Depthwise(int(256*alpha), int(512*alpha), stride=2),
            Depthwise(int(512*alpha), int(512*alpha), stride=1),
            Depthwise(int(512*alpha), int(512*alpha), stride=1),
            Depthwise(int(512*alpha), int(512*alpha), stride=1),
            Depthwise(int(512*alpha), int(512*alpha), stride=1),
            Depthwise(int(512*alpha), int(512*alpha), stride=1),
        )
        # down sample
        self.conv6 = nn.Sequential(
            Depthwise(int(512*alpha), int(1024*alpha), stride=2)
        )
        # down sample
        self.conv7 = nn.Sequential(
            Depthwise(int(1024*alpha), int(1024*alpha), stride=2)
        )

        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))
        self.linear = nn.Linear(int(1024*alpha), num_classes)

        # weights initialization
        if self.init_weights:
            self._initialize_weights()

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = self.conv6(x)
        x = self.conv7(x)
        x = self.avg_pool(x)
        x = x.view(x.size(0), -1)
        x = self.linear(x)
        return x

    # weights initialization function
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)

def mobilenet(alpha=1, num_classes = 2):
    return MobileNet(alpha, num_classes)


@st.cache_resource
def load_model(path, load_full_model=True):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    #root_dir = 'binineni/cuai-cv-project/main/models/'
    root_dir = 'streamlit/models/'

    if load_full_model:
        model = torch.load(root_dir + path, map_location=torch.device('cpu'))
    else:
        # If only model parameters are saved
        model = mobilenet(alpha=1).to(device)
        model.load_state_dict(torch.load(root_dir + path, map_location=device))

    return model

def get_prediction(model, original_image_path, cropped_image_path, use_cropper=False):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()
    # Load the original image or cropped image based on the condition
    image_path = cropped_image_path if use_cropper else original_image_path

    # ë°ì´í„° ì „ì²˜ë¦¬
    transform = transforms.Compose([
        transforms.Resize((76, 76)),  # ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ í†µì¼
        transforms.ToTensor(),  # ì´ë¯¸ì§€ë¥¼ PyTorch tensorë¡œ ë³€í™˜
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
    image = Image.open(image_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0)

    with torch.no_grad():
        output = model(image_tensor)

    pred = output.argmax(dim=1, keepdim=True)
    prob = F.softmax(output, dim=1)[0]

    return pred, prob


# main
# layout = wide : í™”ë©´ ì„¤ì • ë””í´íŠ¸ê°’ì„ ì™€ì´ë“œë¡œ
st.set_page_config(page_title="ì•ˆêµ¬ì§ˆí™˜")

st.title("ì•ˆêµ¬ì§ˆí™˜ ì˜ˆì¸¡ í”„ë¡œí† íƒ€ì…")
st.divider()

st.sidebar.title("ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ")

model_paths = [
    'pinkeye_MobileNet_model_full.pth', #ê²°ë§‰ì—¼
    'ker_MobileNet_model_full.pth', #ìƒ‰ì†Œì¹¨ì°©ì„±ê°ë§‰ì§ˆí™˜
    'ent_MobileNet_model_full.pth', #ì•ˆê²€ë‚´ë°˜ì¦
    'ble_MobileNet_model.pth', #ì•ˆê²€ì—¼
    'tumor_MobileNet_model_full.pth', #ì•ˆê²€ì¢…ì–‘
    'epi_MobileNet_model_full.pth', #ìœ ë£¨ì¦
    'ns_MobileNet_model_full.pth' #í•µê²½í™”
]

# Load models using st.cache
pinkeye_model = load_model(model_paths[0])
ker_model = load_model(model_paths[1], load_full_model=False)
ent_model = load_model(model_paths[2], load_full_model=False)
ble_model = load_model(model_paths[3])
tumor_model = load_model(model_paths[4])
epi_model = load_model(model_paths[5])
ns_model = load_model(model_paths[6])

#ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬
models = [pinkeye_model, ker_model, ent_model,
          ble_model, tumor_model, epi_model, ns_model
]

# Define disease names corresponding to each model
disease_names = [
    "ê°ë§‰ì—¼",
    "ìƒ‰ì†Œì¹¨ì°©ì„±ê°ë§‰ì—¼",
    "ì•ˆê²€ë‚´ë°˜ì¦",
    "ì•ˆê²€ì—¼",
    "ì•ˆê²€ì¢…ì–‘",
    "ìœ ë£¨ì¦",
    "í•µê²½í™”"
]

#Constant
cropped_image_path = "data/cropped_image.jpg"
img_path = "data/upload.jpg"

def main():
    # Upload an image and set some options for demo purposes
    img_file = st.sidebar.file_uploader(label='Upload a file', type=['png', 'jpg'])

    st.sidebar.title("Cropper")
    use_cropper = st.sidebar.checkbox(label="Use Cropper", value=False)

    if img_file:
        image = Image.open(img_file)
        st.image(image, caption='Uploaded Image', use_column_width=True)

        # ëª¨ë¸ ì˜ˆì¸¡ì— ì‚¬ìš©í•˜ê¸° ìœ„í•´ image ì €ì¥
        image.save(img_path, format='JPEG')

        if use_cropper:
            st.divider()
            st.info("ê²€ì‚¬í•˜ê³  ì‹¶ì€ ëˆˆ ë¶€ìœ„ë¥¼ í™•ëŒ€í•´ ì£¼ì„¸ìš”.")
            box_color = st.sidebar.color_picker(label="Box Color", value='#0000FF')
            aspect_choice = st.sidebar.radio(label="Aspect Ratio", options=["1:1", "16:9", "4:3", "2:3", "Free"])
            aspect_dict = {
                "1:1": (1, 1),
                "16:9": (16, 9),
                "4:3": (4, 3),
                "2:3": (2, 3),
                "Free": None
            }
            aspect_ratio = aspect_dict[aspect_choice]

            # Get a cropped image from the frontend
            cropped_image = st_cropper(image, realtime_update=True, box_color=box_color,
                                       aspect_ratio=aspect_ratio)
            st.write("Preview")
            _ = cropped_image.thumbnail((150, 150))
            st.image(cropped_image)

            # cropped image ì €ì¥
            cropped_image.save(cropped_image_path, format='JPEG')

        else:
            st.caption("ì´ë¯¸ì§€ë¥¼ Cropí•˜ì‹œë ¤ë©´, Cropper ì²´í¬ë°•ìŠ¤ë¥¼ í´ë¦­í•´ ì£¼ì„¸ìš”.")

    # ì˜ˆì¸¡ ì‹¤í–‰ ë²„íŠ¼
    st.sidebar.title("Predict")
    pred_button = st.sidebar.button("Predict!")
    pred_list = []
    prob_list = []  # ë¼ë²¨ì´ 0ì¼ í™•ë¥ (ë³‘ ì—†ì„ í™•ë¥ )

    if pred_button:
        try:
            if 'cropped_image' in locals() and use_cropper:  # Check if cropped_image exists and cropper is used
                for model in models:
                    pred, prob = get_prediction(model, img_path, cropped_image_path, use_cropper=True)
                    pred_list.append(pred)
                    prob_list.append(prob)
            else:
                for model in models:
                    pred, prob = get_prediction(model, img_path, cropped_image_path, use_cropper=False)
                    pred_list.append(pred)
                    prob_list.append(prob)
        except Exception as e:
            print("error : ", e)

        #ì˜ˆì¸¡ ë¼ë²¨ì´ 1ì¸ ì§ˆë³‘ ì €ì¥
        suspicious_diseases = [disease_names[i] for i, pred in enumerate(pred_list) if pred.item() == 1]

        if suspicious_diseases:
            st.divider()
            st.error("ë‹¤ìŒê³¼ ê°™ì€ ì•ˆêµ¬ì§ˆí™˜ì´ ì˜ì‹¬ë©ë‹ˆë‹¤.", icon="ğŸš¨")
            st.title("")
            # Display a list of suspicious diseases with improved formatting
            for i, disease in enumerate(suspicious_diseases):
                st.markdown(f"""<span style="font-size: 25px; color: #333333;"> - **{disease}**</span>""", unsafe_allow_html=True)
            st.title("")
            # You can add additional information or styling as needed
            st.info("ì´ ê²°ê³¼ëŠ” ì˜í•™ì ì¸ ì¡°ì–¸ì´ë‚˜ ì§„ë‹¨ì„ ëŒ€ì‹ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì „ë¬¸ì˜ì™€ ìƒë‹´í•´ ì£¼ì„¸ìš”.")
        else:
            st.divider()
            st.info("ê±´ê°•í•œ ìƒíƒœì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()

